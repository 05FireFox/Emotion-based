{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praneet\\AppData\\Local\\Temp\\ipykernel_25368\\3205346132.py:4: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  review_df=pd.read_json('../dataset/reviews.jl',lines=True,encoding='utf-8')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m content=pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mcg_content_based.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m collaborative=pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mcg_collaborative.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m review_df=\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../dataset/reviews.jl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m game_df_original=pd.read_json(\u001b[33m'\u001b[39m\u001b[33m../dataset/games.jl\u001b[39m\u001b[33m'\u001b[39m,lines=\u001b[38;5;28;01mTrue\u001b[39;00m,encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Praneet\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:815\u001b[39m, in \u001b[36mread_json\u001b[39m\u001b[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[39m\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Praneet\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1012\u001b[39m, in \u001b[36mJsonReader.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1010\u001b[39m         data = ensure_str(\u001b[38;5;28mself\u001b[39m.data)\n\u001b[32m   1011\u001b[39m         data_lines = data.split(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m         obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_combine_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_lines\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1014\u001b[39m     obj = \u001b[38;5;28mself\u001b[39m._get_object_parser(\u001b[38;5;28mself\u001b[39m.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Praneet\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1040\u001b[39m, in \u001b[36mJsonReader._get_object_parser\u001b[39m\u001b[34m(self, json)\u001b[39m\n\u001b[32m   1038\u001b[39m obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m     obj = \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33mseries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1043\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Praneet\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1176\u001b[39m, in \u001b[36mParser.parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1174\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   1175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1176\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Praneet\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1392\u001b[39m, in \u001b[36mFrameParser._parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1388\u001b[39m orient = \u001b[38;5;28mself\u001b[39m.orient\n\u001b[32m   1390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m orient == \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1391\u001b[39m     \u001b[38;5;28mself\u001b[39m.obj = DataFrame(\n\u001b[32m-> \u001b[39m\u001b[32m1392\u001b[39m         \u001b[43mujson_loads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1393\u001b[39m     )\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m orient == \u001b[33m\"\u001b[39m\u001b[33msplit\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1395\u001b[39m     decoded = {\n\u001b[32m   1396\u001b[39m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ujson_loads(json, precise_float=\u001b[38;5;28mself\u001b[39m.precise_float).items()\n\u001b[32m   1398\u001b[39m     }\n",
      "\u001b[31mValueError\u001b[39m: Expected object or value"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "content=pd.read_csv('cg_content_based.csv')\n",
    "collaborative=pd.read_csv('cg_collaborative.csv')\n",
    "review_df=pd.read_json('../dataset/reviews.jl',lines=True,encoding='utf-8')\n",
    "game_df_original=pd.read_json('../dataset/games.jl',lines=True,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=content[['user_id','product_id','recommended']]\n",
    "collaborative=collaborative[['user_id','product_id','recommended']]\n",
    "\n",
    "#Merging the datasets to find the common rows between them\n",
    "merged_df = pd.merge(content, collaborative, on=['user_id', 'product_id','recommended'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly rearrgaing the dataset\n",
    "merged_df=merged_df.sample(merged_df.shape[0], random_state=50)\n",
    "\n",
    "#Getting 80 percentage of the data as training data\n",
    "merged_df_train=merged_df.head(int(len(merged_df)*(80/100)))\n",
    "merged_df_test= merged_df[~merged_df.index.isin(merged_df_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivot table creation for collaborative filtering\n",
    "user_game_df = pd.pivot_table(merged_df_train,index=['user_id'], columns=['product_id'], values='recommended')\n",
    "\n",
    "#Finding df_tags for content-based filtering \n",
    "game_df = game_df_original[['tags','id']].dropna(subset=['tags', 'id'])\n",
    "game_df = game_df.assign(genres=game_df['tags'].str.split(', ')).explode('tags')\n",
    "game_df = game_df[['tags','id']]\n",
    "one_hot_df = pd.get_dummies(game_df['tags'], prefix='tags')\n",
    "result_df = pd.concat([game_df['id'], one_hot_df], axis=1)\n",
    "df_tags = result_df.groupby('id').sum()\n",
    "df_tags.index = df_tags.index.astype(int)\n",
    "df_tags.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_colla(user_id):\n",
    "\n",
    "    # Getting games played by the particular user_id\n",
    "    random_user_df = user_game_df[user_game_df.index == user_id]\n",
    "    games_watched = random_user_df.columns[random_user_df.notna().any()].tolist()\n",
    "\n",
    "    # Restricting columns to only the games played by the particular user\n",
    "    games_watched_df = user_game_df[games_watched]\n",
    "    user_game_count = games_watched_df.T.notnull().sum()\n",
    "    user_game_count = user_game_count.reset_index()\n",
    "    user_game_count.columns = [\"user_id\", \"game_count\"]\n",
    "    users_same_games = user_game_count[user_game_count[\"game_count\"] > 0][\"user_id\"]\n",
    "    final_df = pd.concat([games_watched_df[games_watched_df.index.isin(users_same_games.values)],\n",
    "                          random_user_df[games_watched]])\n",
    "\n",
    "    # Finding correlation between users who have played the same games played the particular user\n",
    "    correlation_df = final_df.T.corr(\n",
    "        method='kendall').unstack().sort_values().drop_duplicates()\n",
    "    correlation_df = pd.DataFrame(correlation_df, columns=[\"corr\"])\n",
    "    correlation_df.index.names = ['user_id_1', 'user_id_2']\n",
    "    correlation_df = correlation_df.reset_index()\n",
    "\n",
    "    # Finding positively correlated users\n",
    "    positive_corr_users = correlation_df[(correlation_df[\"user_id_1\"] == user_id) & (\n",
    "        correlation_df[\"corr\"] >= 0)][[\"user_id_2\", \"corr\"]].reset_index(drop=True)\n",
    "    positive_corr_users = positive_corr_users.sort_values(by='corr', ascending=False)\n",
    "    positive_corr_users.rename(columns={\"user_id_2\": \"user_id\"}, inplace=True)\n",
    "    positive_corr_users_ratings = positive_corr_users.merge(\n",
    "        review_df[[\"user_id\", \"product_id\", \"recommended\"]], how='inner')\n",
    "    positive_corr_users_ratings = positive_corr_users_ratings[positive_corr_users_ratings[\"user_id\"] != user_id]\n",
    "    positive_corr_users_ratings['weighted_rating'] = positive_corr_users_ratings['corr'] * \\\n",
    "        positive_corr_users_ratings['recommended']\n",
    "\n",
    "    recommendation_df = positive_corr_users_ratings.groupby(\n",
    "        'product_id').agg({\"weighted_rating\": \"mean\"})\n",
    "    recommendation_df = recommendation_df.reset_index()\n",
    "    recommendation_df.sort_values(by='weighted_rating', ascending=False).head()\n",
    "    games_to_be_recommend = recommendation_df[recommendation_df[\"weighted_rating\"] > 0].sort_values(\n",
    "        \"weighted_rating\", ascending=False)\n",
    "    final_game_suggestions = games_to_be_recommend.merge(\n",
    "        game_df_original[[\"id\", \"title\"]], left_on='product_id', right_on='id')[['product_id', 'weighted_rating']]\n",
    "    final_game_suggestions = final_game_suggestions.values.tolist()\n",
    "    return final_game_suggestions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def recommendation_content(user_id):\n",
    "\n",
    "    # Creating a user vector (user profile)\n",
    "    random_user_vec = merged_df_train[merged_df_train.user_id == user_id][[\n",
    "        'product_id', 'recommended']]\n",
    "    random_user_vec.set_index('product_id', inplace=True)\n",
    "    random_user_vec.fillna(0, inplace=True)\n",
    "    recommended_game_count = len(random_user_vec[random_user_vec > 0])\n",
    "    random_user_vec = random_user_vec.squeeze()\n",
    "    game_tag_pivot = df_tags.mul(random_user_vec, axis=0)\n",
    "    game_tag_pivot.fillna(0, inplace=True)\n",
    "    user_profile = game_tag_pivot.sum()/recommended_game_count\n",
    "\n",
    "    # Finding already played and reviewed games\n",
    "    played_games = random_user_vec.index\n",
    "\n",
    "    # Finding similarity between user profile and games (via tags)\n",
    "    cos_sim = cosine_similarity([user_profile], df_tags)\n",
    "    cos_sim_df = pd.DataFrame(\n",
    "        {'cosine_similarity': cos_sim[0], 'ind': df_tags.index})\n",
    "\n",
    "    # Making sure already playes games are not recommended\n",
    "    reco_games = cos_sim_df[~(cos_sim_df.ind.isin(played_games))].sort_values(\n",
    "        by='cosine_similarity', ascending=False)[['ind', 'cosine_similarity']]\n",
    "\n",
    "    reco_games.set_index('ind', inplace=True)\n",
    "    final_game_suggestions = game_df_original[game_df_original.id.isin(\n",
    "        reco_games.index)][['id']]\n",
    "    final_game_suggestions = final_game_suggestions.merge(\n",
    "        reco_games, left_on='id', right_on='ind')[['id', 'cosine_similarity']]\n",
    "    final_game_suggestions = final_game_suggestions.values.tolist()\n",
    "    return final_game_suggestions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate hybrid recommendations\n",
    "def hybrid_weight(colla_list,content_list):\n",
    "    if(len(colla_list)>0) & (len(content_list)>0):\n",
    "        df1 = pd.DataFrame(colla_list)\n",
    "        df1.columns =['product_id','similarity']\n",
    "        df2 = pd.DataFrame(content_list)\n",
    "        df2.columns =['product_id','similarity']            \n",
    "        joined_results= df1.merge(df2, on='product_id',how='inner')\n",
    "        joined_results['weighted_avg']=(joined_results['similarity_x']*0.2)+(joined_results['similarity_y']*0.8)\n",
    "        joined_results=joined_results[['product_id','weighted_avg']]\n",
    "    elif len(colla_list)>0:\n",
    "        joined_results = pd.DataFrame(colla_list)\n",
    "        joined_results.columns =['product_id','similarity']\n",
    "    elif len(content_list)>0:\n",
    "        joined_results = pd.DataFrame(content_list)\n",
    "        joined_results.columns =['product_id','similarity']\n",
    "    else:\n",
    "        joined_results = pd.DataFrame([])\n",
    "        joined_results.columns =['product_id','similarity']\n",
    "\n",
    "    return joined_results.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hybrid ROC Calculation\n",
    "from collections import defaultdict\n",
    "\n",
    "def ROC(list_of_users,threshold):\n",
    "    \n",
    "    user_predictions = defaultdict(list)\n",
    "   \n",
    "    for uid in list_of_users:\n",
    "        pred=hybrid_weight(recommendation_colla(uid),recommendation_content(uid))\n",
    "        user_predictions[uid].append(pred)        \n",
    "    \n",
    "    om_specificity = dict()\n",
    "    sensitivity = dict()\n",
    "    for uid, games in user_predictions.items():      \n",
    "        \n",
    "        # Recommended liked games\n",
    "        reco_l_games = [product_id for product_id, weighted_avg in games[0] if weighted_avg > threshold]\n",
    "        reco_l_games = set(reco_l_games)     \n",
    "\n",
    "        #Recommended unliked games\n",
    "        reco_ul_games = [product_id for product_id, weighted_avg in games[0] if weighted_avg < threshold]\n",
    "        reco_ul_games=set(reco_ul_games)\n",
    "\n",
    "        common_games_t = merged_df_test[merged_df_test.user_id==uid]        \n",
    "\n",
    "        ul_games = common_games_t[common_games_t.recommended == 0]['product_id'].values.tolist()\n",
    "        ul_games=set(ul_games)\n",
    "        l_games = common_games_t[common_games_t.recommended == 1]['product_id'].values.tolist()\n",
    "        l_games=set(l_games)     \n",
    "\n",
    "        #Confusion matrix calculation\n",
    "        true_positives = l_games & reco_l_games\n",
    "        false_negatives = ul_games & reco_ul_games\n",
    "        false_positives = ul_games & reco_l_games\n",
    "        true_negatives = l_games & reco_ul_games        \n",
    "\n",
    "        om_specificity[uid] = len(false_positives) / (len(false_positives) + len(true_negatives)) if (len(false_positives) + len(true_negatives)) != 0 else 0\n",
    "        sensitivity[uid] = len(true_positives) / (len(true_positives) + len(false_negatives)) if (len(true_positives) + len(false_negatives)) != 0 else 0    \n",
    "\n",
    "    return sensitivity, om_specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     number_list.append(s + i*number_gap)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#Cumulating list of users common between training and testing data    \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m list_of_users = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[43mmerged_df_train\u001b[49m.user_id) & \u001b[38;5;28mset\u001b[39m(merged_df_test.user_id))\n\u001b[32m     11\u001b[39m list_of_users=[\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m list_of_users]\n",
      "\u001b[31mNameError\u001b[39m: name 'merged_df_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Creating a list of threshold values for ROC_AUC calculation\n",
    "number_list = []\n",
    "s = 0\n",
    "e = 1\n",
    "number_gap = 0.1\n",
    "for i in range(int((e-s)/number_gap)+1):\n",
    "    number_list.append(s + i*number_gap)\n",
    "\n",
    "#Cumulating list of users common between training and testing data    \n",
    "list_of_users = list(set(merged_df_train.user_id) & set(merged_df_test.user_id))\n",
    "list_of_users=[int(i) for i in list_of_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing user list for testing\n",
    "pd.DataFrame({'user list': list_of_users}).to_csv(\"user_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9117647058823529\n",
      "0.6176470588235294\n",
      "0.9117647058823529\n",
      "0.611764705882353\n",
      "0.9088235294117647\n",
      "0.5757002801120449\n",
      "0.8719049741108564\n",
      "0.47843031151854687\n",
      "0.7789734974760821\n",
      "0.3448349036584331\n",
      "0.6257352413061755\n",
      "0.1803743641978936\n",
      "0.3576563142739613\n",
      "0.04819749646739265\n",
      "0.1019140989729225\n",
      "0.011519607843137256\n",
      "0.029411764705882353\n",
      "0.0\n",
      "0.029411764705882353\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Sensitivity and 1-Specificity calculation for ROC_AUC calcuation \n",
    "x =list()\n",
    "y =list()\n",
    "for i in number_list:\n",
    "    sensitivity, om_specificity = ROC(list_of_users,i)\n",
    "    print(sum(sens for sens in sensitivity.values()) / len(sensitivity))\n",
    "    print(sum(oms for oms in om_specificity.values()) / len(om_specificity))\n",
    "    y.append(sum(sens for sens in sensitivity.values()) / len(sensitivity))\n",
    "    x.append(sum(oms for oms in om_specificity.values()) / len(om_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m auc\n\u001b[32m      3\u001b[39m fig, ax = plt.subplots()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m ax.plot(\u001b[43mx\u001b[49m, y, color=\u001b[33m'\u001b[39m\u001b[33mgreen\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m ax.set_xlabel(\u001b[33m'\u001b[39m\u001b[33m1-specificity\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m ax.set_ylabel(\u001b[33m'\u001b[39m\u001b[33msensitivity\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'x' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x, y, color='green')\n",
    "ax.set_xlabel('1-specificity')\n",
    "ax.set_ylabel('sensitivity')\n",
    "\n",
    "plt.savefig('ROC_Hybrid.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m roc_auc = auc(\u001b[43mx\u001b[49m, y)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Print the AUC value\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(roc_auc)\n",
      "\u001b[31mNameError\u001b[39m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "roc_auc = auc(x, y)\n",
    "\n",
    "# Print the AUC value\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving data for final plot\n",
    "hybrid_df = pd.DataFrame({'x': x, 'y': y})\n",
    "hybrid_df.to_csv(\"ROC_hybrid_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. LOADING INPUTS ---\n",
      "Content Rows: 8909\n",
      "Collaborative Rows: 178757\n",
      "\n",
      "--- 2. MERGING SCORES ---\n",
      "Overlapping Pairs: 8909\n",
      "\n",
      "--- 3. CALCULATING HYBRID ---\n",
      "\n",
      "--- 4. SAVING ROC ---\n",
      "Hybrid AUC: 0.9807\n",
      "Saved 'ROC_hybrid_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "\n",
    "print(\"--- 1. LOADING INPUTS ---\")\n",
    "\n",
    "try:\n",
    "    df_content = pd.read_csv('cg_content_based.csv')\n",
    "    df_collab = pd.read_csv('cg_collaborative.csv')\n",
    "    print(f\"Content Rows: {len(df_content)}\")\n",
    "    print(f\"Collaborative Rows: {len(df_collab)}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Run previous notebooks first.\")\n",
    "    sys.exit()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. MERGE\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n--- 2. MERGING SCORES ---\")\n",
    "\n",
    "# Merge on User and Product\n",
    "merged_df = pd.merge(df_content, df_collab, on=['user_id', 'product_id'], how='inner')\n",
    "\n",
    "# Handle duplicate 'actual' columns if they exist (actual_x, actual_y)\n",
    "if 'actual_x' in merged_df.columns:\n",
    "    merged_df['actual'] = merged_df['actual_x']\n",
    "\n",
    "print(f\"Overlapping Pairs: {len(merged_df)}\")\n",
    "\n",
    "if merged_df.empty:\n",
    "    print(\"Error: No overlap between models. Ensure both scripts predicted on the same User-Game pairs.\")\n",
    "    sys.exit()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. HYBRID SCORE\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n--- 3. CALCULATING HYBRID ---\")\n",
    "\n",
    "def normalize(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "# Normalize scores to 0-1\n",
    "merged_df['content_norm'] = normalize(merged_df['content_score'])\n",
    "merged_df['collab_norm'] = normalize(merged_df['collab_score'])\n",
    "\n",
    "# Weighted Average (0.6 Collab + 0.4 Content)\n",
    "W_COLLAB = 0.6\n",
    "W_CONTENT = 0.4\n",
    "merged_df['hybrid_score'] = (merged_df['collab_norm'] * W_COLLAB) + (merged_df['content_norm'] * W_CONTENT)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. EVALUATION\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n--- 4. SAVING ROC ---\")\n",
    "\n",
    "if 'actual' in merged_df.columns and len(merged_df['actual'].unique()) > 1:\n",
    "    fpr, tpr, _ = roc_curve(merged_df['actual'], merged_df['hybrid_score'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"Hybrid AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    pd.DataFrame({'x': fpr, 'y': tpr}).to_csv(\"ROC_hybrid_data.csv\", index=False)\n",
    "    print(\"Saved 'ROC_hybrid_data.csv'\")\n",
    "else:\n",
    "    print(\"Error: Ground truth missing or contains only one class (all 0s or all 1s).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
